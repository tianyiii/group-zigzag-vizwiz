{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lxmert_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VjSepcZB44v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f94d414-6800-423b-8804-a4b00243c66a"
      },
      "source": [
        "# !git clone https://github.com/airsplay/lxmert.git\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B65W1MGyCRqi"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/lxmert\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U0YSIOPPABN",
        "outputId": "6a3011fc-488e-4746-8418-1cd46f6cd43e"
      },
      "source": [
        "#1. reformat train.json, val.json \n",
        "# !wget https://ivc.ischool.utexas.edu/VizWiz_final/vqa_data/Annotations.zip\n",
        "# !unzip Annotations.zip\n",
        "import json\n",
        "with open('Annotations/train.json') as f1:\n",
        "  train_json = json.load(f1)\n",
        "with open('Annotations/val.json') as f2:\n",
        "  val_json = json.load(f2)\n",
        "\n",
        "answer_vocabs = set()\n",
        "\n",
        "new_trains = []\n",
        "for train in train_json:\n",
        "  new_train = {}\n",
        "  new_train[\"img_id\"] = train[\"image\"]\n",
        "  new_train[\"question_id\"] = train[\"image\"]\n",
        "  new_train[\"sent\"] = train[\"question\"]\n",
        "  label_dict = {}\n",
        "  for ans in train[\"answers\"]:\n",
        "    answer = ans[\"answer\"]\n",
        "    answer_vocabs.add(answer)\n",
        "    label_dict[answer] = min(round(label_dict.get(answer,0) + 0.3, 1), 1.0)\n",
        "  new_train[\"label\"] = label_dict\n",
        "  new_trains.append(new_train)\n",
        "with open('data/vqa/train.json', 'w') as outfile:\n",
        "    json.dump(new_trains, outfile)\n",
        "\n",
        "\n",
        "new_vals = []\n",
        "for val in val_json:\n",
        "  new_val = {}\n",
        "  new_val[\"img_id\"] = val[\"image\"]\n",
        "  new_val[\"question_id\"] = val[\"image\"]\n",
        "  new_val[\"sent\"] = val[\"question\"]\n",
        "  label_dict = {}\n",
        "  for ans in val[\"answers\"]:\n",
        "    answer = ans[\"answer\"]\n",
        "    answer_vocabs.add(answer)\n",
        "    label_dict[answer] = min(round(label_dict.get(answer,0) + 0.3, 1), 1.0)\n",
        "  new_val[\"label\"] = label_dict\n",
        "  new_vals.append(new_val)\n",
        "with open('data/vqa/minival.json', 'w') as outfile:\n",
        "    json.dump(new_vals, outfile)\n",
        "\n",
        "print(len(new_trains))\n",
        "print(len(new_vals))\n",
        "print(len(answer_vocabs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20523\n",
            "4319\n",
            "48730\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TztCKNcxUHi7"
      },
      "source": [
        "#2. generate ans2label and label2ans file\n",
        "label2ans = list(answer_vocabs)\n",
        "with open('data/vqa/trainval_label2ans.json', 'w') as outfile:\n",
        "    json.dump(label2ans, outfile)\n",
        "ans2label = {}\n",
        "for i,ans in enumerate(label2ans):\n",
        "  ans2label[ans] = i\n",
        "with open('data/vqa/trainval_ans2label.json', 'w') as outfile:\n",
        "    json.dump(ans2label, outfile)\n",
        "\n",
        "!mkdir -p snap/pretrained \n",
        "!wget https://nlp.cs.unc.edu/data/model_LXRT.pth -P snap/pretrained"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NrhuJXDCROu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dddee78c-e766-46f3-c86c-578067e07ab7"
      },
      "source": [
        "!mkdir -p data/vizwiz_imgfeat\n",
        "# !wget https://nlp.cs.unc.edu/data/lxmert_data/vizwiz/vizwiz/valid_obj36.tsv -P data/mscoco_imgfeat\n",
        "# !wget 'https://s3.us-east-2.amazonaws.com/cmumonkey/36_vizwiz_val.pkl' -P data/vizwiz_imgfeat\n",
        "!wget 'https://s3.us-east-2.amazonaws.com/cmumonkey/36_vizwiz_train.pkl' -P data/vizwiz_imgfeat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-16 02:32:16--  https://s3.us-east-2.amazonaws.com/cmumonkey/36_vizwiz_train.pkl\n",
            "Resolving s3.us-east-2.amazonaws.com (s3.us-east-2.amazonaws.com)... 52.219.96.106\n",
            "Connecting to s3.us-east-2.amazonaws.com (s3.us-east-2.amazonaws.com)|52.219.96.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7122021558 (6.6G) [binary/octet-stream]\n",
            "Saving to: ‘data/vizwiz_imgfeat/36_vizwiz_train.pkl’\n",
            "\n",
            "36_vizwiz_train.pkl 100%[===================>]   6.63G  75.8MB/s    in 1m 53s  \n",
            "\n",
            "2021-04-16 02:34:09 (60.2 MB/s) - ‘data/vizwiz_imgfeat/36_vizwiz_train.pkl’ saved [7122021558/7122021558]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNDM8LpYfB8K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "44de2e67-b36f-443d-873f-7387001a279f"
      },
      "source": [
        "import pickle\n",
        "with open('data/vizwiz_imgfeat/36_vizwiz_train.pkl', 'rb') as f:\n",
        "    train_img_feat = pickle.load(f)\n",
        "with open('data/vizwiz_imgfeat/36_vizwiz_val.pkl', 'rb') as f:\n",
        "    val_img_feat = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f4e40eaec988>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/vizwiz_imgfeat/36_vizwiz_train.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_img_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/vizwiz_imgfeat/36_vizwiz_val.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mval_img_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlr-pswfSe4"
      },
      "source": [
        "print(val_img_feat[0].keys())\n",
        "print(val_img_feat[0]['info'].item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTlUcg_iFVyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb1d539d-1c28-46c7-8cae-4696f77f74a6"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.8.1+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.41.1)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/b3/8c889dd3d5ae47a9c4468cc20ef980adc4a16f06f0937ab33f78b58b5eda/boto3-1.17.53-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->-r requirements.txt (line 4)) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->-r requirements.txt (line 4)) (3.7.4.3)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.21.0,>=1.20.53\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/4e/232e261b739534e216f28d935a06c44840221c3476ebcdb411cd0fc2bf16/botocore-1.20.53-py2.py3-none-any.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 14.9MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/89/0cb4e92c239e6425b9b0035227b8cdf9d3d098a5c9e95632c3815df63a09/s3transfer-0.3.7-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 10)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 10)) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 10)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 10)) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.53->boto3->-r requirements.txt (line 8)) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.53->boto3->-r requirements.txt (line 8)) (1.15.0)\n",
            "\u001b[31mERROR: botocore 1.20.53 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.17.53 botocore-1.20.53 jmespath-0.10.0 s3transfer-0.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8pcHHwuFPX_"
      },
      "source": [
        "!bash run/vqa_finetune.bash 0 vizwiz_tiny --tiny"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWeCsUH7XkYT"
      },
      "source": [
        "!bash run/vqa_finetune.bash 0 vizwiz_all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FElI7gqjdsLo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18e1a15d-2c80-42f2-b28d-a391841600b8"
      },
      "source": [
        "!bash run/vqa_test.bash 0 vizwiz_all_results --test valid --load snap/vqa/vizwiz_all/BEST"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train\n",
            "Load 20523 data from split(s) train.\n",
            "Start to load Faster-RCNN detected objects from data/vizwiz_imgfeat/36_vizwiz_train.pkl\n",
            "Loaded 512 images in file data/vizwiz_imgfeat/36_vizwiz_train.pkl in 98 seconds.\n",
            "Use 444 data in torch dataset\n",
            "\n",
            "LXRT encoder with 9 l_layers, 5 x_layers, and 5 r_layers.\n",
            "BertAdam Total Iters: 52\n",
            "Load model from snap/vqa/vizwiz_all/BEST\n",
            "valid\n",
            "Load 4319 data from split(s) valid.\n",
            "Start to load Faster-RCNN detected objects from data/vizwiz_imgfeat/36_vizwiz_val.pkl\n",
            "Loaded 7748 images in file data/vizwiz_imgfeat/36_vizwiz_val.pkl in 44 seconds.\n",
            "Use 4317 data in torch dataset\n",
            "\n",
            "0.4786889043317073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJCbzAY4A6x8",
        "outputId": "a7a2c82e-c132-4990-a929-41426df4a9fc"
      },
      "source": [
        "import sys\n",
        "import csv\n",
        "import base64\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "FIELDNAMES = [\"img_id\", \"img_h\", \"img_w\", \"objects_id\", \"objects_conf\",\n",
        "              \"attrs_id\", \"attrs_conf\", \"num_boxes\", \"boxes\", \"features\"]\n",
        "\n",
        "def load_obj_pkl(fname, topk=None):\n",
        "  data = []\n",
        "  start_time = time.time()\n",
        "  print(\"Start to load Faster-RCNN detected objects from %s\" % fname)\n",
        "  with open(fname,'rb') as f:\n",
        "    img_feat = pickle.load(f)\n",
        "    for i, item in enumerate(img_feat):\n",
        "      item['img_h'] = int(item['image_h'])\n",
        "      item['img_w'] = int(item['image_w'])\n",
        "      item['num_boxes'] = int(item['num_bbox'])\n",
        "      \n",
        "      boxes = item['num_boxes']\n",
        "      decode_config = [\n",
        "              ('objects_id', (boxes, ), np.int64),\n",
        "              ('objects_conf', (boxes, ), np.float32),\n",
        "              ('attrs_id', (boxes, ), np.int64),\n",
        "              ('attrs_conf', (boxes, ), np.float32)\n",
        "          ]\n",
        "      for key, shape, dtype in decode_config:\n",
        "        # item[key] = np.frombuffer(base64.b64decode(item['info'].item().get(key)), dtype=dtype)\n",
        "        item[key] = item['info'].item().get(key)\n",
        "        item[key] = item[key].reshape(shape)\n",
        "        item[key].setflags(write=False)\n",
        "      \n",
        "      # item['boxes'] = np.frombuffer(base64.b64decode(item['bbox']), dtype=np.float32)\n",
        "      item['boxes'] = item['bbox']\n",
        "      item['boxes'] = item['boxes'].reshape((boxes, 4))\n",
        "      item['boxes'].setflags(write=False) \n",
        "\n",
        "      # item['features'] = np.frombuffer(base64.b64decode(item['x']), dtype=np.float32)\n",
        "      item['features'] = item['x']\n",
        "      item['features'] = item['features'].reshape((boxes, -1))\n",
        "      item['features'].setflags(write=False) \n",
        "\n",
        "      item['img_id'] = item['info'].item().get('image_id') + \".jpg\" \n",
        "      \n",
        "\n",
        "      data.append(item['features'].shape[0])\n",
        "      if topk is not None and len(data) == topk:\n",
        "          break\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(\"Loaded %d images in file %s in %d seconds.\" % (len(data), fname, elapsed_time))\n",
        "    return data\n",
        "\n",
        "\n",
        "data = load_obj_pkl('data/vizwiz_imgfeat/36_vizwiz_train.pkl')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start to load Faster-RCNN detected objects from data/vizwiz_imgfeat/36_vizwiz_train.pkl\n",
            "Loaded 23952 images in file data/vizwiz_imgfeat/36_vizwiz_train.pkl in 44 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAtieXSrFuRb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61dc6c90-2ba1-40c3-9e67-316fdcdaf897"
      },
      "source": [
        "from collections import Counter\n",
        "print(Counter(data))\n",
        "# {32, 34, 36, 21}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({36: 23948, 21: 2, 34: 1, 32: 1})\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}